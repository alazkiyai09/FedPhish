batch_size: 4
cache_dir: data/cache
data_path: data/raw/phishing_emails_hf.csv
device: cuda
dropout: 0.1
early_stopping_metric: auprc
early_stopping_patience: 3
fp16: true
gradient_accumulation_steps: 1
learning_rate: 2.0e-05
log_dir: logs
logging_steps: 50
lora_alpha: 16
lora_dropout: 0.1
lora_rank: 8
max_grad_norm: 1.0
max_length: 512
model_name: bert-base-uncased
num_epochs: 1
num_labels: 2
output_dir: checkpoints
save_steps: 500
seed: 42
special_tokens:
- '[SUBJECT]'
- '[BODY]'
- '[URL]'
- '[SENDER]'
test_split: 0.2
train_split: 0.6
truncation_strategy: head_tail
use_lora: false
use_special_tokens: true
use_wandb: false
val_split: 0.2
wandb_entity: null
wandb_project: phishing-detection-transformers
warmup_ratio: 0.1
weight_decay: 0.01
